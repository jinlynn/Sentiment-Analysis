{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a80944c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer # Tokenizer that removes punctuation\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8ff8929",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cleaned_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1eed998",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Tokenize the text\n",
    "    tokens = tokenizer.tokenize(text.lower())\n",
    "    \n",
    "    # Remove stopwords and lemmatize\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens if token not in stop_words]\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3ad451a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                      [virginamerica, dhepburn, said]\n",
       "1    [virginamerica, plus, added, commercial, exper...\n",
       "2    [virginamerica, today, must, mean, need, take,...\n",
       "3    [virginamerica, really, aggressive, blast, obn...\n",
       "4             [virginamerica, really, big, bad, thing]\n",
       "Name: processed_text, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['processed_text'] = df['text'].apply(preprocess_text)\n",
    "df['processed_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d77b90fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    }
   ],
   "source": [
    "max_length = df['processed_text'].apply(lambda x: len(x)).max()\n",
    "print(max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d42729df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    14485.000000\n",
       "mean        10.490369\n",
       "std          4.132354\n",
       "min          1.000000\n",
       "25%          7.000000\n",
       "50%         11.000000\n",
       "75%         13.000000\n",
       "max         26.000000\n",
       "Name: processed_text, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['processed_text'].apply(lambda x: len(x)).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed34bc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_to_remove = {\n",
    "    'virginamerica', 'jetblue', 'usairways', 'united',\n",
    "    'southwest', 'southwestair', 'americanair', 'delta',\n",
    "    'rt', 'url', 'http'\n",
    "}\n",
    "\n",
    "def is_valid_word(word):\n",
    "    return (\n",
    "        isinstance(word, str) and                    # ensure input is a string\n",
    "        len(word) > 2 and                            # longer than 2 characters\n",
    "        word.lower() not in words_to_remove and       # not in custom junk list\n",
    "        re.fullmatch(r'[A-Za-z]+', word) is not None and  # only letters\n",
    "        re.search(r'(.)\\1{2,}', word) is None        # no repeating chars like \"aaa\"\n",
    "    )\n",
    "\n",
    "word_counts_grouped = (\n",
    "    df[df['airline_sentiment'] == 'negative'] # filter for negative sentiment tweets\n",
    "    .explode('processed_text') # explode token list into separate rows\n",
    "    .rename(columns={'processed_text': 'keyword'})\n",
    "    .loc[:, ['airline', 'negativereason', 'tweet_id', 'keyword']] # select relevant columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf089fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out invalid words\n",
    "word_counts_grouped = word_counts_grouped.dropna(subset=['keyword'])\n",
    "\n",
    "word_counts_grouped = word_counts_grouped[word_counts_grouped['keyword'].apply(is_valid_word)]\n",
    "\n",
    "# group and count keywords\n",
    "word_counts_grouped = (\n",
    "    word_counts_grouped\n",
    "    .groupby(['keyword', 'airline', 'negativereason'])\n",
    "    .size()\n",
    "    .reset_index(name='count')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "956db441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove words that appear only once\n",
    "word_counts_grouped = word_counts_grouped[word_counts_grouped['count'] > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fa8b5a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>airline</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aadvantage</td>\n",
       "      <td>American</td>\n",
       "      <td>Customer Service Issue</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aadvantage</td>\n",
       "      <td>US Airways</td>\n",
       "      <td>Customer Service Issue</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>abc</td>\n",
       "      <td>Delta</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>able</td>\n",
       "      <td>American</td>\n",
       "      <td>Cancelled Flight</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>able</td>\n",
       "      <td>American</td>\n",
       "      <td>Customer Service Issue</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33986</th>\n",
       "      <td>zero</td>\n",
       "      <td>US Airways</td>\n",
       "      <td>Customer Service Issue</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33989</th>\n",
       "      <td>zero</td>\n",
       "      <td>United</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33990</th>\n",
       "      <td>zero</td>\n",
       "      <td>United</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33991</th>\n",
       "      <td>zero</td>\n",
       "      <td>United</td>\n",
       "      <td>Customer Service Issue</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33993</th>\n",
       "      <td>zero</td>\n",
       "      <td>United</td>\n",
       "      <td>Lost Luggage</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11410 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          keyword     airline          negativereason  count\n",
       "3      aadvantage    American  Customer Service Issue      2\n",
       "4      aadvantage  US Airways  Customer Service Issue      2\n",
       "16            abc       Delta              Bad Flight      2\n",
       "31           able    American        Cancelled Flight      3\n",
       "32           able    American  Customer Service Issue     12\n",
       "...           ...         ...                     ...    ...\n",
       "33986        zero  US Airways  Customer Service Issue      3\n",
       "33989        zero      United              Bad Flight      2\n",
       "33990        zero      United              Can't Tell      2\n",
       "33991        zero      United  Customer Service Issue      4\n",
       "33993        zero      United            Lost Luggage      2\n",
       "\n",
       "[11410 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "506699f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "288"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(word_counts_grouped['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07d3a11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts_grouped.to_csv('keywords.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "airline_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
